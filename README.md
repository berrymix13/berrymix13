<div align="center">

  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=200&section=header&text=Hi%20I'm%20berryJiny!&fontSize=40&fontColor=ffffff&gradient=7928CA,FF0080" />

  <p align="center">
    <img src="https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExNTRrbWwya3B5YmxtYWU3YnJpYnFpcWxoeTF0bzM5eHp4aDlmdTRmdiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/RZY86mGjaASPAjVAcs/giphy.gif" width="200" height="200"/>
  </p>

  <br>

  I'm currently working on **Vision-based Autonomous Robot Systems** ğŸ¤–  
  Really do hope to be a âœ¨Data Scientist & Robotic Developerâœ¨ someday!

</div>

<br>

## ğŸš€ Featured Projects

### ğŸ† AGV Vision Pick-and-Place System
> Real-time 3D vision-based autonomous pick-and-place using mobile robot (AGV) + robotic arm

A complete mobile manipulation system that combines AGV navigation, 3D object detection, and precise robotic manipulation for autonomous pick-and-place operations.

| Main Features                     | Technologies Used               |
|----------------------------------|---------------------------------|
| Autonomous Navigation            | ROS Noetic, SLAM, AMCL          |
| 3D Object Detection & Pose Est.  | YOLOv11, RealSense D435         |
| Mobile Manipulation              | myAGV, MyCobot 280, MoveIt      |
| Hand-Eye Calibration             | Eye-to-Hand, OpenCV, PGO        |
| Real-time Coordinate Transform   | Point Cloud Processing, FastAPI |

ğŸ‘‰ [View Project Repository](https://github.com/berrymix13/agv-vision-pick-and-place)

---

### ğŸ”¥ Vision Manipulator
> A robot system that understands natural language, detects objects with YOLO, and executes Grasp & Place

Natural language-driven manipulation system integrating GPT, computer vision, and industrial robot control.

| Main Features                     | Technologies Used               |
|----------------------------------|---------------------------------|
| Natural Language Command Parsing | OpenAI GPT API                  |
| Object & Keypoint Detection      | YOLOv11, HRNet                  |
| 3D Transformation & Calibration  | Eye-in-Hand, OpenCV             |
| Robot Control Pipeline           | ROS2, UR10, MoveIt2             |

ğŸ‘‰ [View Project Repository](https://github.com/berrymix13/vision-manipulator)

<br>

## ğŸ§  Currently Interested In

- **Mobile Manipulation & Multi-Robot Systems**
  - AGV navigation with SLAM (gmapping, AMCL)
  - Coordinated control between mobile base and manipulator
  
- **Robot Vision & 3D Perception**
  - YOLO-based object detection & pose estimation
  - Hand-Eye calibration (Eye-in-Hand / Eye-to-Hand)
  - Point cloud processing with RealSense depth cameras
  
- **Robot Control & Motion Planning**
  - ROS / ROS2 system integration
  - MoveIt / MoveIt2 motion planning
  - Real-time robot control pipelines

- **AI & Robotics Integration**
  - GPT + Vision + Robot control fusion
  - Real-time vision-language-action models
  - Autonomous task execution systems

<br>

### ğŸŒ± I'm currently learning

- Multi-robot coordination and task planning
- Advanced hand-eye calibration techniques (PGO, Tsai-Lenz)
- Real-time 3D object pose estimation
- ROS action servers for complex robot behaviors
- Vision-based autonomous navigation systems

<br>

## ğŸ“ Education
- **Konkuk University â€“ Graduate School**  
  M.S. in Big Data and Applied Statistics  
  Research focus on computer vision, AI robotics, and autonomous systems  
  ğŸ‡°ğŸ‡· ê±´êµ­ëŒ€í•™êµ ëŒ€í•™ì› ì‘ìš©í†µê³„í•™ê³¼ ë¹…ë°ì´í„° ì „ê³µ ì¬í•™ ì¤‘


- **Kyonggi University**  
  B.A. in Applied Statistics (Major)  
  B.A. in Convergent Data Engineering (Double Major)  
  ğŸ‡°ğŸ‡· ê²½ê¸°ëŒ€í•™êµ ê²½ì œí•™ë¶€ ì‘ìš©í†µê³„í•™ê³¼ / ìœµí•©ë°ì´í„°ê³µí•™ ë³µìˆ˜ì „ê³µ

<br>

## ğŸ› ï¸ Tech Stack

### Robotics
![ROS](https://img.shields.io/badge/ROS-22314E?style=flat&logo=ros&logoColor=white)
![ROS2](https://img.shields.io/badge/ROS2-22314E?style=flat&logo=ros&logoColor=white)
![MoveIt](https://img.shields.io/badge/MoveIt-0078D4?style=flat&logoColor=white)

### Computer Vision & AI
![Python](https://img.shields.io/badge/Python-3776AB?style=flat&logo=python&logoColor=white)
![OpenCV](https://img.shields.io/badge/OpenCV-5C3EE8?style=flat&logo=opencv&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)
![YOLO](https://img.shields.io/badge/YOLO-00FFFF?style=flat&logoColor=black)

### Development Tools
![Git](https://img.shields.io/badge/Git-F05032?style=flat&logo=git&logoColor=white)
![Linux](https://img.shields.io/badge/Linux-FCC624?style=flat&logo=linux&logoColor=black)
![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)

<br>

## ğŸ“Š GitHub Stats

<p align="center">
  <img src="https://github-readme-stats.vercel.app/api?username=berrymix13&show_icons=true&theme=radical" />
</p>

<br>

## ğŸ“« Contact

- ğŸ“§ Email: sujini7773@gmail.com
- ğŸ’¼ GitHub: [@berrymix13](https://github.com/berrymix13)

---

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&height=100&section=footer" />
</p>
